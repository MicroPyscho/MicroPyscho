{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroPyscho/MicroPyscho/blob/main/ANN_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnM1QgNHuHku"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "spgOy-hMvZmW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqkQ43TOED3S"
      },
      "source": [
        "Load dataset and replace all +ve and -ve infinite values with NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve49yXz-vfR-"
      },
      "outputs": [],
      "source": [
        "star_df = pd.read_csv(\"/content/drive/MyDrive/Star_df dataset\").replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "if \"Unnamed: 0\" in star_df.columns:\n",
        "  star_df.drop(columns =[\"Unnamed: 0\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = star_df['ficincome'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "8JB78S84L5IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_sum = ['_CGSRDP049', '_CGVSDP047', '_CGVSDP048', '_CGVSDP049',\n",
        "                    '_CGVSDP050', '_CGVSDP053', '_CGVSDP054', '_CGVSDP055', '_CGVSDP056', '_CGVSDP057', '_CGVSDP058']\n",
        "star_df['SDG5_9&12_17'] = star_df[var_sum].sum(axis=1)\n",
        "star_df.drop(columns=var_sum, inplace=True)"
      ],
      "metadata": {
        "id": "Au4zzMtwi3qE"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_sum2 = ['_ENERDP062', '_ENERDP063', '_ENERDP068', \"Target\", \"CCIndexd1\", \"SUS_report\", \"ENV_committee\"]\n",
        "star_df['waste_redctn_efforts'] = (star_df[var_sum2].sum(axis=1) / 7).clip(0, 1)\n",
        "star_df.drop(columns=var_sum2, inplace=True)\n"
      ],
      "metadata": {
        "id": "QawOBhXPi67s"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_df['_ENRRO04V'] = (star_df['_ENRRO04V'] - star_df['_ENRRO04V'].mean()) / star_df['_ENRRO04V'].std()\n",
        "var_sum3 = [\"_ENPIDP066\", \"_ENPIDP069\", \"_ENRRO04V\", \"EcoInn_score\"]\n",
        "star_df['clean_tech_efrts'] = (star_df[var_sum3].sum(axis=1) / 4).clip(0, 1)\n",
        "star_df.drop(columns=var_sum3, inplace=True)"
      ],
      "metadata": {
        "id": "Kd1dzzSbjRxa"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_sum4 = [\"_SOCODP011\", \"_SOCOO10V\", \"CrisisMgt\"]\n",
        "star_df['anomaly_reportng_efrts'] = (star_df[var_sum4].sum(axis=1) / 3).clip(0, 1)\n",
        "star_df.drop(columns=var_sum4, inplace=True)"
      ],
      "metadata": {
        "id": "GTHRXhZ1jfWa"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_df['_SODODP017'] = (star_df['_SODODP017'] - star_df['_SODODP017'].mean()) / star_df['_SODODP017'].std()\n",
        "star_df['_SODODP019'] = (star_df['_SODODP019'] - star_df['_SODODP019'].mean()) / star_df['_SODODP019'].std()\n",
        "var_sum5 = [\"_SODODP019\", \"_SODODP017\"]\n",
        "star_df['women_rpresntn'] = (star_df[var_sum5].sum(axis=1) / 2).clip(0, 1)\n",
        "star_df.drop(columns=var_sum5, inplace=True)"
      ],
      "metadata": {
        "id": "RzCAYs9-joDL"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_sum6= ['climatevul_capacity', 'climatevul_exposure', 'climatevul_sensitivity',\n",
        "                    'climate_vul', 'climate_economic', 'climate_governance',\n",
        "                    'climate_readiness', 'climate_social']\n",
        "star_df['climate_preparedness'] = star_df[var_sum6].sum(axis=1)\n",
        "star_df.drop(columns=var_sum6, inplace=True)"
      ],
      "metadata": {
        "id": "THK5COidkKva"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_avg = ['CO2eGDP', 'CO2eGDP_PPP2017', 'CO2eGDP_PPP']\n",
        "star_df['avgCO2_GDP'] = star_df[var_avg].mean(axis=1)\n",
        "star_df.drop(columns=var_avg, inplace=True)"
      ],
      "metadata": {
        "id": "1jIXEpTIkvSy"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_df['bal_of_tradeGDP%'] = star_df['ExportsGDP'] - star_df['ImportsGDP']\n",
        "var_std = ['GDP_K2015', 'GDPg', 'GDP_percap2015', 'GDPg_percap', \"MktCapGDP\", \"GovtDebtGDP\", \"bal_of_tradeGDP%\", \"TradeGDP\"]\n",
        "for var in var_std:\n",
        "    star_df[f'{var}_standardized'] = (star_df[var] - star_df[var].mean()) / star_df[var].std()\n",
        "star_df['gdp_prfmnce'] = star_df[[f'{var}_standardized' for var in var_std]].sum(axis=1)\n",
        "star_df['gdp_prfmnce_rank'] = star_df['gdp_prfmnce'].rank(pct=True) * 100\n",
        "star_df.drop(columns=var_std, inplace=True)"
      ],
      "metadata": {
        "id": "I54ZECbbk0wQ"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "income_class_map = {'High income': 4, 'Upper middle income': 3, 'Lower middle income': 2, 'Low income': 1}\n",
        "star_df['incme_class'] = star_df['ficincome'].map(income_class_map)\n",
        "var_std2 = ['var', 'pvr', 'ger', 'rqr', 'rlr', 'ccr', 'hdi_score', 'incme_class', \"gain\"]\n",
        "for var in var_std2:\n",
        "  star_df[f'{var}_standardized'] = (star_df[var] - star_df[var].mean()) / star_df[var].std()\n",
        "star_df['eco_soc_gov_fctrs'] = star_df[[f'{var}_standardized' for var in var_std2]].sum(axis=1)\n",
        "star_df['eco_soc_gov_fctrs'] = (star_df['eco_soc_gov_fctrs'] - star_df['eco_soc_gov_fctrs'].min()) / (star_df['eco_soc_gov_fctrs'].max() - star_df['eco_soc_gov_fctrs'].min()) * 100\n",
        "star_df.drop(columns=var_std2, inplace=True)"
      ],
      "metadata": {
        "id": "2HubuUjRlHay"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_df['dvsrty&inclsn_score'] = (star_df['_TRDIRDS'] + star_df['_TRDIRIS']) / 2\n",
        "\n",
        "star_df['total_emissns'] = star_df['_ENERDP023'] + star_df['_ENERDP123'] + star_df[\"_ENERO03V\"]\n",
        "star_df['Net_FDI_GDP'] = star_df['FDI_INFGDP'] - star_df['FDI_OUTGDP']\n",
        "\n",
        "star_df['avg_EPS'] = (star_df['_EPS'] + star_df['_EPS2MN']) / 2\n",
        "star_df['DCred2PrvSctr_GDP'] = (star_df['DCredPvtGDP'] - star_df['DCredPvtGDP'].mean()) / star_df['DCredPvtGDP'].std()\n",
        "star_df['agg_net_cash_flow'] = star_df['_WC04860'] + star_df['_WC04870'] + star_df['_WC04890']\n",
        "star_df['operating_profit'] = star_df['_WC01250'] - star_df['_WC01249']\n",
        "star_df[\"abs_sales_growth\"] = star_df['sgrowth'] - star_df['sicsgrowth']\n",
        "star_df.rename(columns={'_WC03151': 'working_capital'}, inplace=True)\n",
        "star_df.rename(columns={\"_WC01001\": \"net_revenue\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC01201\": \"R&D\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC03501\": \"common_equity\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC03998\": \"total_capital\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC08106\": \"current_ratio\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC08126\": \"invntry_hold_days\"}, inplace=True)\n",
        "star_df.rename(columns={\"_WC08366\": \"net_prfit_margin\"}, inplace=True)\n",
        "star_df.rename(columns={\"roe\": \"retrn_on_equity\"}, inplace=True)\n",
        "star_df.rename(columns={\"_CGBSO19\": \"board_gndr_div%\"}, inplace=True)\n",
        "star_df.rename(columns={\"_CGSCORE\": \"govnce_pilr_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"_CGVSDP046\": \"govnce_pilr_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENERDP024\": \"dirct_cemissions\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENERDP025\": \"indirct_cemissions\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENERO27V\": \"scope1\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENERO28V\": \"scope2\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENRRDP033\": \"total_enrgy_use\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENRRDP046\": \"renwbl_enrgy_use\"}, inplace=True)\n",
        "star_df.rename(columns={\"_ENSCORE\": \"envrmt_pilr_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"_TRESGCS\": \"ESG_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"_TRESGCGVSS\": \"CSR_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"_TRESGENERS\": \"emissn_score\"}, inplace=True)\n",
        "star_df.rename(columns={\"INTSpread\": \"Intrst_rate_spread\"}, inplace=True)\n",
        "star_df.rename(columns={\"pop_score\": \"population\"}, inplace=True)\n",
        "\n",
        "\n",
        "#star_df['working_capital'] = star_df['_WC02201'] - star_df['_WC02999']"
      ],
      "metadata": {
        "id": "KvTpr46arZkY"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_A = [\n",
        "    'DSCD', 'ticker', 'exchange', 'WC06011', 'WC07040', '_EPS', '_EPS2MN', '_MVC',\n",
        "    '_P', '_WC01051', '_WC01084', '_WC01249', '_WC01100', '_WC01250', '_WC01401',\n",
        "    '_WC02001', '_WC02051', '_WC02101', '_WC02201', '_WC02501', '_WC02999',\n",
        "    '_WC03101', '_WC03255', '_WC03351', '_WC03480', '_WC03995', '_WC04551',\n",
        "    '_WC04601', '_WC04860', '_WC04870', '_WC04890', '_WC05201', '_WC05476',\n",
        "    '_WC05502', '_WC08101', '_WC08321', '_WC08301', '_WC08316', '_WC08366',\n",
        "    '_WC09504', '_WC18193', '_WC18199', '_WC18198', 'ffi5', 'cashna', 'cash2sales',\n",
        "    'ppe', 'Size', 'logsales', 'logppe', 'firmage37', 'logage', 'tlta', 'tdta',\n",
        "    'tdmv', 'clta', 'cata', 'apta', 'arta', 'arsale', 'apcogs', 'nettcsale', 'dep',\n",
        "    'roa', 'ros', 'ebitta', 'tobinqe', 'mb', 'capexppe', 'dcashta', 'dcashsales',\n",
        "    'dcashna', 'sgrowth', 'sicsgrowth', 'nwccta', 'divta', 'tri', 'divchg', 'lppe',\n",
        "    'lsize', 'llogsales', 'lcfw', 'lroa', 'lroe', 'ltobinq', 'lcapexppe', 'larta',\n",
        "    'lapta', 'llogemp', 'ldep', 'llogage', 'llogage2', 'lcashna', 'lcashsales',\n",
        "    'lcash2ta', 'lempgrowth', 'lcapexrdta', 'lcash2sales', 'lcash2na', 'wwindex',\n",
        "    'kzindex', 'saindex', 'mwail', 'zscore', 'zscoree', '_CGSRDP049', '_CGVSDP046',\n",
        "    '_CGVSDP047', '_CGVSDP048', '_CGVSDP049', '_CGVSDP050', '_CGVSDP053',\n",
        "    '_CGVSDP054', '_CGVSDP055', '_CGVSDP056', '_CGVSDP057', '_CGVSDP058',\n",
        "    '_ENERDP033', '_ENERDP062', '_ENERO32V', '_SOCODP037', '_SODODP0151',\n",
        "    '_SOEQO08V', '_TRDIRDs', '_TRDIRIS', '_TRESGS', '_TRESGENPIS', 'TCE', 'DCE',\n",
        "    'INDCE', 'logTCE', 'logDCE', 'logINDCE', 'logEMScore', 'TCETA', 'DCETA',\n",
        "    'ENVInitiatives', 'logENVInvScore', 'EnergyUse', 'RenEnergyUse',\n",
        "    'EnergyUseSale', 'logEnergyUse', 'logResUse_score', 'logMgtScore',\n",
        "    'logSHScore', 'logCSRScore', 'logCMScore', 'logHRScore', 'logPRScore',\n",
        "    'GOVScore', 'SOSScore', 'ESG_Comp', 'MgersFem', 'BODDIV', 'EXEDIV',\n",
        "    'SnrExecCompTA', 'SnrExecCompSale', 'CrisisMgt', 'EmissionsTrdg', 'SDG13',\n",
        "    'Climate_gov', 'ENV_Prod', 'ENV_Asset', 'Eco_Prod', 'RespUse_Prod',\n",
        "    'CleanTech', 'EcoInn_score', 'ENV_train', 'MgtTrg', 'ESGC', 'CO2eGDP',\n",
        "    'CO2eGDP_PPP2017', 'CO2eGDP_PPP', 'FDI_OUTGDP', 'FDI_INFGDP', 'DCredPvtGDP',\n",
        "    'GDP_Cur', 'GDP_K2015', 'GDPg', 'GDP_percap2015', 'GDPg_percap', 'MktCapGDP',\n",
        "    'GovtDebtGDP', 'bal_of_tradeGDP%', 'INFL_conpx', 'INTPayExp', 'INTPayRev',\n",
        "    'RealINT', 'gdp_score', 'var', 'pvr', 'ger', 'rqr', 'rlr', 'ccr', 'hdi_score',\n",
        "    'incme_class', 'gain', 'ficincome', 'climatevul_capacity', 'climatevul_exposure',\n",
        "    'climatevul_sensitivity', 'climate_vul', 'climate_economic', 'climate_governance',\n",
        "    'climate_readiness', 'climate_social'\n",
        "]\n",
        "\n",
        "list_B = [\n",
        "    '_CGSRDP049', '_CGVSDP047', '_CGVSDP048', '_CGVSDP049',\n",
        "    '_CGVSDP050', '_CGVSDP053', '_CGVSDP054', '_CGVSDP055', '_CGVSDP056', '_CGVSDP057', '_CGVSDP058', '_ENERDP062', '_ENERDP063', '_ENERDP068', \"Target\", \"CCIndexd1\", \"SUS_report\", \"ENV_committee\", \"_ENPIDP066\", \"_ENPIDP069\", \"_ENRRO04V\", \"EcoInn_score\", \"_SOCODP011\", \"_SOCOO10V\", \"CrisisMgt\", \"_SODODP019\", \"_SODODP017\", 'climatevul_capacity', 'climatevul_exposure', 'climatevul_sensitivity',\n",
        "                    'climate_vul', 'climate_economic', 'climate_governance',\n",
        "                    'climate_readiness', 'climate_social', 'CO2eGDP', 'CO2eGDP_PPP2017', 'CO2eGDP_PPP',  'GDP_K2015', 'GDPg', 'GDP_percap2015', 'GDPg_percap', \"MktCapGDP\", \"GovtDebtGDP\", \"bal_of_tradeGDP%\", \"TradeGDP\", 'var', 'pvr', 'ger', 'rqr', 'rlr', 'ccr', 'hdi_score', 'incme_class', \"gain\", \"_ENERO03V\", '_ENERDP123', '_ENERDP023', '_TRDIRIS', '_TRDIRDS', 'FDI_OUTGDP', 'FDI_INFGDP', '_EPS2MN', '_EPS', 'DCredPvtGDP', '_WC04870', '_WC01249', '_WC01250', '_WC04890', '_WC04860', 'sicsgrowth', 'sgrowth'\n",
        "]\n",
        "\n",
        "# Remove duplicates from list_B in list_A\n",
        "list_A = [variable for variable in list_A if variable not in list_B]\n",
        "\n",
        "print(list_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnwoPBC4wA7L",
        "outputId": "b25cef64-548e-48ff-a22a-a91fd9f8bc69"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DSCD', 'ticker', 'exchange', 'WC06011', 'WC07040', '_MVC', '_P', '_WC01051', '_WC01084', '_WC01100', '_WC01401', '_WC02001', '_WC02051', '_WC02101', '_WC02201', '_WC02501', '_WC02999', '_WC03101', '_WC03255', '_WC03351', '_WC03480', '_WC03995', '_WC04551', '_WC04601', '_WC05201', '_WC05476', '_WC05502', '_WC08101', '_WC08321', '_WC08301', '_WC08316', '_WC08366', '_WC09504', '_WC18193', '_WC18199', '_WC18198', 'ffi5', 'cashna', 'cash2sales', 'ppe', 'Size', 'logsales', 'logppe', 'firmage37', 'logage', 'tlta', 'tdta', 'tdmv', 'clta', 'cata', 'apta', 'arta', 'arsale', 'apcogs', 'nettcsale', 'dep', 'roa', 'ros', 'ebitta', 'tobinqe', 'mb', 'capexppe', 'dcashta', 'dcashsales', 'dcashna', 'nwccta', 'divta', 'tri', 'divchg', 'lppe', 'lsize', 'llogsales', 'lcfw', 'lroa', 'lroe', 'ltobinq', 'lcapexppe', 'larta', 'lapta', 'llogemp', 'ldep', 'llogage', 'llogage2', 'lcashna', 'lcashsales', 'lcash2ta', 'lempgrowth', 'lcapexrdta', 'lcash2sales', 'lcash2na', 'wwindex', 'kzindex', 'saindex', 'mwail', 'zscore', 'zscoree', '_CGVSDP046', '_ENERDP033', '_ENERO32V', '_SOCODP037', '_SODODP0151', '_SOEQO08V', '_TRDIRDs', '_TRESGS', '_TRESGENPIS', 'TCE', 'DCE', 'INDCE', 'logTCE', 'logDCE', 'logINDCE', 'logEMScore', 'TCETA', 'DCETA', 'ENVInitiatives', 'logENVInvScore', 'EnergyUse', 'RenEnergyUse', 'EnergyUseSale', 'logEnergyUse', 'logResUse_score', 'logMgtScore', 'logSHScore', 'logCSRScore', 'logCMScore', 'logHRScore', 'logPRScore', 'GOVScore', 'SOSScore', 'ESG_Comp', 'MgersFem', 'BODDIV', 'EXEDIV', 'SnrExecCompTA', 'SnrExecCompSale', 'EmissionsTrdg', 'SDG13', 'Climate_gov', 'ENV_Prod', 'ENV_Asset', 'Eco_Prod', 'RespUse_Prod', 'CleanTech', 'ENV_train', 'MgtTrg', 'ESGC', 'GDP_Cur', 'INFL_conpx', 'INTPayExp', 'INTPayRev', 'RealINT', 'gdp_score', 'ficincome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_dp = ['DSCD', 'ticker', 'exchange', 'WC06011', 'WC07040', '_MVC', '_P', '_WC01051', '_WC01084', '_WC01100']\n",
        "star_df.drop(columns=col_dp, inplace=True)"
      ],
      "metadata": {
        "id": "HBqvbkNFwts_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXwhFWSrxMpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop variables in list_A from star_df\n",
        "star_df.drop(columns=list_A, inplace=True)"
      ],
      "metadata": {
        "id": "88hjpr5HwQsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "star_df = star_df.loc[:, ~star_df.columns.str.endswith('_standardized')]"
      ],
      "metadata": {
        "id": "rBklXQAunyVV"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col_name, count in star_df.count().items():\n",
        "    print(f\"{col_name}: {count}\")"
      ],
      "metadata": {
        "id": "XjZOwDVhp2BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create a DataFrame to store the log-transformed variables\n",
        "log_star_df = pd.DataFrame()\n",
        "\n",
        "# Iterate through each column in star_df\n",
        "for col in star_df.columns:\n",
        "    # Check if the column contains numerical data\n",
        "    if np.issubdtype(star_df[col].dtype, np.number):\n",
        "        # Apply log transformation and add it to log_star_df\n",
        "        log_star_df[col+'_log'] = np.log(star_df[col])\n",
        "    else:\n",
        "        # If the column contains non-numerical data, simply copy it to log_star_df\n",
        "        log_star_df[col] = star_df[col]\n",
        "\n",
        "# Now log_star_df contains log-transformed variables (for numerical columns)\n"
      ],
      "metadata": {
        "id": "DakakOqrasKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_star_df.to_csv('/content/drive/My Drive/log_star_df.csv', index=False)"
      ],
      "metadata": {
        "id": "BqM0-8_gmUsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col_name, count in log_star_df.count().items():\n",
        "    print(f\"{col_name}: {count}\")"
      ],
      "metadata": {
        "id": "Cq6CfuXungD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQJkP516EUZz"
      },
      "source": [
        "Exclude all object dtype variable in preparation for ANN and CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft7cEYEFvrsQ"
      },
      "outputs": [],
      "source": [
        "#star_df = star_df.select_dtypes(exclude=['object'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6keTWlDuwOkW"
      },
      "outputs": [],
      "source": [
        "star_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_So7-ZqY3tBS"
      },
      "outputs": [],
      "source": [
        "star_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caCQPLYvDy5F"
      },
      "source": [
        "Replace any residual \"-\" in any variable with the mean of the variable column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht58YGdQk_X_"
      },
      "outputs": [],
      "source": [
        "star_df.replace('-', pd.NA, inplace=True)\n",
        "star_df = star_df.apply(pd.to_numeric, errors='coerce')\n",
        "column_means = star_df.mean(skipna=True)\n",
        "star_df.fillna(column_means, inplace=True)\n",
        "\n",
        "print(\"Updated DataFrame:\")\n",
        "print(star_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPvqmqovEo_n"
      },
      "source": [
        "Split the variables according to their dtypes and note them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0i0u9Lw8Poq"
      },
      "outputs": [],
      "source": [
        "obj_cols = star_df.select_dtypes(include=['object'])\n",
        "\n",
        "int_cols = star_df.select_dtypes(include=[\"int\", \"int64\", \"float\", \"float64\"])\n",
        "\n",
        "print(\"Object Columns:\")\n",
        "print(obj_cols.columns)\n",
        "print(\"\\nInteger Columns:\")\n",
        "print(int_cols.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grkxAuscE64J"
      },
      "source": [
        "Do the same for all non-object dtype to note where they fall between \"int\", \"int64\", \"float\", \"float64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMTOmip27TA3"
      },
      "outputs": [],
      "source": [
        "obj_cols = int_cols.select_dtypes(include=['object'])\n",
        "\n",
        "int_cols = int_cols.select_dtypes(include=[\"int\", \"int64\", \"float\", \"float64\"])\n",
        "\n",
        "print(\"Object Columns:\")\n",
        "print(obj_cols.columns)\n",
        "print(\"\\nInteger Columns:\")\n",
        "print(int_cols.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOUgjMsQEDRB"
      },
      "outputs": [],
      "source": [
        "int_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r876qwXkEXD"
      },
      "source": [
        "#Random Forest Regression to predict AI Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7OrHxIGkDOa"
      },
      "outputs": [],
      "source": [
        "# Assuming int_cols is your DataFrame with integer format ai_score\n",
        "A = int_cols.drop(columns=[\"ai_score\"])\n",
        "B = int_cols[\"ai_score\"]\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "A_train, A_test, B_train, B_test = train_test_split(A, B, test_size=0.3, random_state=42)\n",
        "\n",
        "# Building the Random Forest regression model\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(A_train, B_train)\n",
        "\n",
        "# Feature importances\n",
        "feature_importances = rf_regressor.feature_importances_\n",
        "\n",
        "# Getting the top 50 features\n",
        "top_50_indices = feature_importances.argsort()[-50:][::-1]\n",
        "top_50_features = A.columns[top_50_indices]\n",
        "top_50_importances = feature_importances[top_50_indices]\n",
        "\n",
        "# Plotting the top 50 features\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.barh(top_50_features, top_50_importances)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 50 Features Using Random Forest Regression')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display most important features at the top\n",
        "plt.savefig('/content/top_50_RFReg.pdf')\n",
        "plt.show()\n",
        "\n",
        "# Predicting on the test set\n",
        "B_pred = rf_regressor.predict(A_test)\n",
        "\n",
        "# Creating a DataFrame to display actual and predicted values side by side\n",
        "results_df = pd.DataFrame({'Actual': B_test, 'Predicted': B_pred})\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00UGlpDBAUZh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculating Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(B_test, B_pred)\n",
        "\n",
        "# Calculating Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(B_test, B_pred)\n",
        "\n",
        "# Calculating R-squared (R2) score\n",
        "r2 = r2_score(B_test, B_pred)\n",
        "\n",
        "# Printing the evaluation metrics\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R2) Score:\", r2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXSt_TUtAWLg"
      },
      "outputs": [],
      "source": [
        "# Saving evaluation metrics to a file\n",
        "with open('/content/evaluation_metrics.txt', 'w') as f:\n",
        "    f.write(\"Mean Absolute Error (MAE): {}\\n\".format(mae))\n",
        "    f.write(\"Mean Squared Error (MSE): {}\\n\".format(mse))\n",
        "    f.write(\"R-squared (R2) Score: {}\\n\".format(r2))\n",
        "\n",
        "# Visualizing actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(B_test, B_pred)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted Values for Random Forest Regression')\n",
        "plt.savefig('/content/actual_vs_predicted_RFReg.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmZL0DK8Cdob"
      },
      "source": [
        "#KNN Classifier to predict AI Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lckobleCA2qn"
      },
      "outputs": [],
      "source": [
        "# Convert ai_ranking to integer format\n",
        "int_cols['ai_ranking'] = int_cols['ai_ranking'].astype(int)\n",
        "\n",
        "# Split the data into features (A) and target variable (B)\n",
        "A = int_cols.drop(columns=[\"ai_ranking\"])\n",
        "B = int_cols[\"ai_ranking\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "A_train, A_test, B_train, B_test = train_test_split(A, B, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "\n",
        "# Train the KNN model\n",
        "knn_classifier.fit(A_train, B_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = knn_classifier.predict(A_train)\n",
        "y_pred_test = knn_classifier.predict(A_test)\n",
        "\n",
        "# Evaluate the model\n",
        "# Accuracy\n",
        "train_accuracy = accuracy_score(B_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(B_test, y_pred_test)\n",
        "\n",
        "# Classification report\n",
        "train_classification_report = classification_report(B_train, y_pred_train)\n",
        "test_classification_report = classification_report(B_test, y_pred_test)\n",
        "\n",
        "print(f'Train Accuracy: {train_accuracy}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "print(\"Train Classification Report:\")\n",
        "print(train_classification_report)\n",
        "\n",
        "print(\"Test Classification Report:\")\n",
        "print(test_classification_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL5wbztmIzb0"
      },
      "outputs": [],
      "source": [
        "metrics_filename = '/content/evaluation_metrics.txt'\n",
        "classification_report_train_filename = '/content/classification_report_train.txt'\n",
        "classification_report_test_filename = '/content/classification_report_test.txt'\n",
        "\n",
        "with open(metrics_filename, 'w') as f:\n",
        "    f.write(f'Train Accuracy: {train_accuracy}\\n')\n",
        "    f.write(f'Test Accuracy: {test_accuracy}\\n')\n",
        "\n",
        "with open(classification_report_train_filename, 'w') as f:\n",
        "    f.write(\"Train Classification Report:\\n\")\n",
        "    f.write(train_classification_report)\n",
        "\n",
        "with open(classification_report_test_filename, 'w') as f:\n",
        "    f.write(\"Test Classification Report:\\n\")\n",
        "    f.write(test_classification_report)\n",
        "\n",
        "# Zip the files\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/evaluation_metrics_and_reports.zip', 'w') as zipf:\n",
        "    for file in [metrics_filename, classification_report_train_filename, classification_report_test_filename]:\n",
        "        zipf.write(file, os.path.basename(file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvySWMa8CUNK"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with actual and predicted rankings\n",
        "compard_df = pd.DataFrame({'Actual': B_test, 'Predicted': y_pred_test})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(compard_df)\n",
        "\n",
        "compard_df = pd.DataFrame({'Actual': B_test, 'Predicted': y_pred_test})\n",
        "\n",
        "# Reset index to have numerical index\n",
        "compard_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Plot the actual and predicted rankings\n",
        "plt.figure(figsize=(10, 6))\n",
        "compard_df.plot(kind='bar', figsize=(14, 8))\n",
        "plt.title('Actual vs Predicted Rankings using KNN Classifier')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Ranking')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/actual_predicteed_KNNC.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVJhOdUWcwhW"
      },
      "source": [
        "Rank the top 50 important features for predicting AI Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqISwHnbjxOl"
      },
      "outputs": [],
      "source": [
        "# Define number of classes\n",
        "num_classes = 5  # Adjust as needed\n",
        "\n",
        "# Discretize the target variable into classes\n",
        "B_train_discretized = np.digitize(B_train, np.arange(0, 101, 100/num_classes))\n",
        "B_test_discretized = np.digitize(B_test, np.arange(0, 101, 100/num_classes))\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(A_train, B_train_discretized)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Get indices of top 50 features\n",
        "top_50_indices = feature_importances.argsort()[-50:][::-1]\n",
        "\n",
        "# Get top 50 feature names\n",
        "top_50_features = A_train.columns[top_50_indices]\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=feature_importances[top_50_indices], y=top_50_features)\n",
        "plt.title('Top 50 Features Importance for AI Ranking Using KNN')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.savefig('/content/feat_importance_KNNC.pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP-I4gJnIz-P"
      },
      "source": [
        "#ANN Model Prediction for AI Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcPffutrFNsA"
      },
      "source": [
        "standardize dataset for ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B0sBaipAGcT"
      },
      "outputs": [],
      "source": [
        "std_cols = (int_cols - int_cols.mean()) / int_cols.std()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_cols = scaler.fit_transform(std_cols)\n",
        "sstar_df = pd.DataFrame(scaled_cols, columns=std_cols.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF0M-8di5iML"
      },
      "outputs": [],
      "source": [
        "X =std_cols.drop(columns=[\"ai_score\"])\n",
        "y = std_cols[\"ai_score\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sew3Q592Ijd6"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dense(1)  # No activation function for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=36, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLcsfU3jKTNp"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/loss_plot.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmCYqchSU3P_"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtauOQfmet6v"
      },
      "outputs": [],
      "source": [
        "vy_test = y_test.values.reshape(-1, 1)\n",
        "inv_ytest = scaler.inverse_transform(np.hstack((np.zeros((len(vy_test), std_cols.shape[1]-1)), vy_test)))\n",
        "\n",
        "vy_pred = y_pred.reshape(-1, 1)\n",
        "inv_ypred = scaler.inverse_transform(np.hstack((np.zeros((len(vy_pred), std_cols.shape[1]-1)), vy_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Je-7OVaaKj3"
      },
      "outputs": [],
      "source": [
        "y_testS = inv_ytest * int_cols['ai_score'].std() + int_cols['ai_score'].mean()\n",
        "y_predS = inv_ypred * int_cols['ai_score'].std() + int_cols['ai_score'].mean()\n",
        "\n",
        "comparison_df = pd.DataFrame({'Actual': y_testS.flatten(), 'Predicted': y_predS.flatten()})\n",
        "\n",
        "# Step 3: Print/visualize the comparison\n",
        "print(comparison_df)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate difference between actual and predicted values\n",
        "difference = np.abs(comparison_df['Actual'] - comparison_df['Predicted'])\n",
        "\n",
        "# Define a color map\n",
        "cmap = plt.get_cmap('coolwarm')  # Choose a colormap\n",
        "norm = plt.Normalize(difference.min(), difference.max())  # Normalize the difference values\n",
        "colors = cmap(norm(difference))\n",
        "\n",
        "# compare using scatter plot\n",
        "plt.scatter(comparison_df['Actual'], comparison_df['Predicted'], c=colors)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Scatterplot of Actual vs Predicted AI Score using ANN')\n",
        "plt.colorbar(label='Absolute Difference')\n",
        "plt.savefig('/content/scatter_plot_ANN.pdf')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# compare using line plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(comparison_df['Actual'], label='Actual', color='blue')\n",
        "plt.plot(comparison_df['Predicted'], label='Predicted', color='red')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Lineplot of Actual vs Predicted AI Score using ANN')\n",
        "plt.legend()\n",
        "plt.savefig('/content/line_plot_ANN.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7fnsb-Qmabu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_testS, y_predS)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_testS, y_predS)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = mean_squared_error(y_testS, y_predS, squared=False)\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = r2_score(y_testS, y_predS)\n",
        "\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "print(\"R-squared:\", r_squared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRI7SHoFmpS2"
      },
      "outputs": [],
      "source": [
        "# Get the weights of the connections between the input layer and the first hidden layer\n",
        "weights = model.layers[0].get_weights()[0]\n",
        "\n",
        "# Calculate feature importance by summing the absolute weights for each feature\n",
        "feature_importance = np.sum(np.abs(weights), axis=1)\n",
        "\n",
        "# Get the indices of the top 50 features\n",
        "top_50_indices = feature_importance.argsort()[-50:][::-1]\n",
        "\n",
        "# Get the names of the top 50 features\n",
        "top_50_features = X_train.columns[top_50_indices]\n",
        "\n",
        "# Plot the feature importance\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.barh(range(len(top_50_features)), feature_importance[top_50_indices], align='center')\n",
        "plt.yticks(range(len(top_50_features)), top_50_features)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 50 Features Importance for AI Score Using ANN')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.savefig('/content/top_50_ANN.pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXssRdYxZYe1"
      },
      "source": [
        "#Random Forest Regression Analysis for AI Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98zfzZ4tZXbO"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Feature importances\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Getting the top 50 features\n",
        "top_50_indices = feature_importances.argsort()[-50:][::-1]\n",
        "top_50_features = X.columns[top_50_indices]\n",
        "top_50_importances = feature_importances[top_50_indices]\n",
        "\n",
        "# Plotting the top 50 features\n",
        "plt.figure(figsize=(20, 16))\n",
        "plt.barh(top_50_features, top_50_importances)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 50 Features')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display most important features at the top\n",
        "plt.savefig('/content/RF_top_50_ANN.pdf')\n",
        "plt.show()\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Creating a DataFrame to display actual and predicted values side by side\n",
        "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Wo55Z5vTzw"
      },
      "source": [
        "#KNN Regression Analysis for AI Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVlb68gZvZDE"
      },
      "outputs": [],
      "source": [
        "A =std_cols.drop(columns=[\"ai_ranking\"])\n",
        "B = std_cols[\"ai_ranking\"]\n",
        "\n",
        "A_train, A_test, B_train, B_test = train_test_split(A, B, test_size =0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmXN_S1090_S"
      },
      "outputs": [],
      "source": [
        "print(B.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZEzEXglvYI8"
      },
      "outputs": [],
      "source": [
        "# Initialize the KNN regressor\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "\n",
        "# Train the KNN model\n",
        "knn_regressor.fit(A_train, B_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = knn_regressor.predict(A_train)\n",
        "y_pred_test = knn_regressor.predict(A_test)\n",
        "\n",
        "# Evaluate the model\n",
        "#RMSE\n",
        "train_rmse = mean_squared_error(B_train, y_pred_train, squared=False)\n",
        "test_rmse = mean_squared_error(B_test, y_pred_test, squared=False)\n",
        "\n",
        "#MAE\n",
        "train_mae = mean_absolute_error(B_train, y_pred_train)\n",
        "test_mae = mean_absolute_error(B_test, y_pred_test)\n",
        "\n",
        "# R-squared\n",
        "train_r2 = r2_score(B_train, y_pred_train)\n",
        "test_r2 = r2_score(B_test, y_pred_test)\n",
        "\n",
        "print(f'Train RMSE: {train_rmse}')\n",
        "print(f'Test RMSE: {test_rmse}')\n",
        "print(f'Train MAE: {train_mae}')\n",
        "print(f'Test MAE: {test_mae}')\n",
        "print(f'Train R-squared: {train_r2}')\n",
        "print(f'Test R-squared: {test_r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KueJjAHP3sqn"
      },
      "outputs": [],
      "source": [
        "compare_df = pd.DataFrame({'Actual': B_test, 'Predicted': y_pred_test})\n",
        "print(compare_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqemoPqpTbvF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame with actual and predicted rankings\n",
        "comparison_df = pd.DataFrame({'Actual': B_test, 'Predicted': y_pred_test})\n",
        "\n",
        "# Reset index to have numerical index\n",
        "comparison_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Plot the actual and predicted rankings\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Bar chart\n",
        "plt.subplot(2, 1, 1)  # 2 rows, 1 column, plot 1\n",
        "comparison_df.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Actual vs Predicted Rankings')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Ranking')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Scatter plot with line\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2\n",
        "plt.scatter(B_train, y_pred_train, label='Training data', color='blue', alpha=0.5)\n",
        "plt.scatter(B_test, y_pred_test, label='Test data', color='red', alpha=0.5)\n",
        "plt.plot([B_train.min(), B_train.max()], [B_train.min(), B_train.max()], 'k--', lw=2)  # Diagonal line\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title('Actual vs Predicted values for AI Ranking Using KNN Regression')\n",
        "plt.savefig('/content/top_50_KNN_Regression.pdf')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAWGH43-1HZD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(B_train, y_pred_train, label='Training data', color='blue', alpha=0.5)\n",
        "plt.scatter(B_test, y_pred_test, label='Test data', color='red', alpha=0.5)\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title('Actual vs Predicted values for KNN Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAg2cpKYob20"
      },
      "outputs": [],
      "source": [
        "# Calculate the absolute difference in predictions when a feature value is perturbed\n",
        "train_feature_importances = np.mean(np.abs(knn_regressor.predict(A_train) - knn_regressor.predict(A_train.values + 0.01)), axis=0)\n",
        "test_feature_importances = np.mean(np.abs(knn_regressor.predict(A_test) - knn_regressor.predict(A_test.values + 0.01)), axis=0)\n",
        "\n",
        "# Get the indices of features sorted by importance\n",
        "train_sorted_indices = train_feature_importances.argsort()[::-1]\n",
        "test_sorted_indices = test_feature_importances.argsort()[::-1]\n",
        "\n",
        "# Get the top 50 features and their importance scores\n",
        "top_train_features = A_train.columns[train_sorted_indices][:50]\n",
        "top_train_scores = train_feature_importances[train_sorted_indices][:50]\n",
        "\n",
        "top_test_features = A_test.columns[test_sorted_indices][:50]\n",
        "top_test_scores = test_feature_importances[test_sorted_indices][:50]\n",
        "\n",
        "# Plot the top 50 features and their importance scores\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.barh(top_train_features, top_train_scores, color='skyblue')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 50 Features Importance - Train Data')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display in descending order\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.barh(top_test_features, top_test_scores, color='skyblue')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 50 Features Importance - Test Data')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display in descending order\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uXqG8y1W0jFfKakHDeG5Gfk8I0UgDaF3",
      "authorship_tag": "ABX9TyNHcYRRy43j8WEkQjvkAtX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}